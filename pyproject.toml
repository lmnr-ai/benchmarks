[project]
name = "openhands-benchmarks"
version = "0.1.0"
description = "OpenHands Benchmarks"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "datasets",
    "huggingface-hub",
    "jinja2",
    "pandas",
    "Pillow",
    "toml",
    "tqdm",
    "openhands-sdk",
    "openhands-tools",
    "unidiff>=0.7.5,<0.8.0",
    "openhands-agent-server",
    "openhands-workspace",
    "modal>=1.1.4",
    "swebench==4.1.0",
    "commit0",
    "pytest-json-report",
    # SWT-Bench dependencies (since the git package doesn't install them properly)
    "requests",
    "docker",
    "python-dotenv",
    "fire",
    "editdistance",
    "GitPython",
    "pyright[nodejs]>=1.1.405",
    "docker-registry-client>=0.5.2",
    "deprecation>=2.1.0",
    "fastmcp>=2.11.3",
    "httpx>=0.27.0",
    "litellm>=1.77.7.dev9",
    "pydantic>=2.11.7",
    "python-frontmatter>=1.1.0",
    "python-json-logger>=3.3.0",
    "tenacity>=9.1.2",
    "websockets>=12",
    "lmnr>=0.7.24",
    "multi-swe-bench>=1.1.1",
]

[project.scripts]
validate-cfg = "benchmarks.scripts.validate_cfg:main"
swebench-infer = "benchmarks.swebench.run_infer:main"
swtbench-infer = "benchmarks.swtbench.run_infer:main"
swebench-eval = "benchmarks.swebench.eval_infer:main"
swtbench-eval = "benchmarks.swtbench.eval_infer:main"
gaia-infer = "benchmarks.gaia.run_infer:main"
gaia-eval = "benchmarks.gaia.eval_infer:main"
commit0-infer = "benchmarks.commit0.run_infer:main"
commit0-eval = "benchmarks.commit0.eval_infer:main"
multiswebench-infer = "benchmarks.multiswebench.run_infer:main"
multiswebench-eval = "benchmarks.multiswebench.eval_infer:main"
openagentsafety-infer = "benchmarks.openagentsafety.run_infer:main"
swebenchmultimodal-infer = "benchmarks.swebenchmultimodal.run_infer:main"
swebenchmultimodal-eval = "benchmarks.swebenchmultimodal.eval_infer:main"

[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
where = ["."]
include = ["benchmarks"]

[tool.setuptools]
# Install the top-level sitecustomize module so Python auto-loads our Modal logging patch.
py-modules = ["sitecustomize"]

[dependency-groups]
dev = [
    "pre-commit>=4.3.0",
    "psutil>=7.0.0",
    "pyright>=1.1.405",
    "ruff>=0.12.10",
    "pycodestyle>=2.12.0",
    "pytest>=8.0.0",
    "pytest-cov>=6.0.0",
    "pytest-forked>=1.6.0",
]

# Ruff configuration
[tool.ruff]
target-version = "py312"
line-length = 88

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.ruff.lint]
select = ["E", "F", "I"]
ignore = ["E501"]

[tool.ruff.lint.isort]
known-first-party = ["benchmarks", "openhands"]
combine-as-imports = true
force-single-line = false
lines-after-imports = 2

[tool.uv.sources]
openhands-sdk = { workspace = true }
openhands-tools = { workspace = true }
openhands-workspace = { workspace = true }
openhands-agent-server = { workspace = true }
swt-bench = { git = "https://github.com/logic-star-ai/swt-bench.git" }

[tool.uv.workspace]
members = [
  "vendor/software-agent-sdk/openhands-sdk",
  "vendor/software-agent-sdk/openhands-tools",
  "vendor/software-agent-sdk/openhands-workspace",
  "vendor/software-agent-sdk/openhands-agent-server",
]
